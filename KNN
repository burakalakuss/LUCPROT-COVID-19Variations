# ===============================================================
# LUCPROT + KNN Model for COVID-19 Variant Classification
# ===============================================================

from Bio import Entrez, SeqIO
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from tensorflow.keras.utils import to_categorical

# ===============================================================
# 1. CONFIGURE NCBI ENTREZ
# ===============================================================

Entrez.email = "your_email@example.com"  # NCBI requires an email identifier
search_term = "COVID-19 variants[gene] AND SARS-CoV-2[organism]"

# ===============================================================
# 2. FETCH DATA FROM NCBI GENE DATABASE
# ===============================================================

handle = Entrez.esearch(db="gene", term=search_term)
record = Entrez.read(handle)
gene_ids = record["IdList"]

sequences = []
labels = []

for gene_id in gene_ids:
    summary_handle = Entrez.efetch(db="gene", id=gene_id, rettype="fasta", retmode="text")
    data = summary_handle.read()
    summary_handle.close()
    
    # Extract FASTA sequence (simplified parsing)
    seq_lines = [line.strip() for line in data.split("\n") if line and not line.startswith(">")]
    seq = "".join(seq_lines)
    if seq:
        sequences.append(seq)
        labels.append("variant")  # label assignment (customize if needed)

print(f"Fetched {len(sequences)} sequences from NCBI.")

# ===============================================================
# 3. LUCPROT ENCODING
# ===============================================================

def lucas_sequence(n):
    L = [2, 1]
    for i in range(2, n):
        L.append(L[-1] + L[-2])
    return L[:n]

def lucprot_encode(sequence):
    amino_acids = sorted(list("ACDEFGHIKLMNPQRSTVWY"))
    lucas_vals = lucas_sequence(len(amino_acids))
    mapping = dict(zip(amino_acids, lucas_vals))
    return [mapping[aa] for aa in sequence if aa in mapping]

encoded_sequences = [lucprot_encode(seq) for seq in sequences]
max_len = max(len(seq) for seq in encoded_sequences)
X = np.array([np.pad(seq, (0, max_len - len(seq))) for seq in encoded_sequences])
y = np.array(labels)

# ===============================================================
# 4. PREPROCESSING
# ===============================================================

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# ===============================================================
# 5. GRID SEARCH KNN
# ===============================================================

param_grid = {
    "n_neighbors": list(range(1, 31)),
    "metric": ["euclidean", "manhattan", "minkowski"],
    "weights": ["uniform", "distance"]
}

knn = KNeighborsClassifier()

grid = GridSearchCV(knn, param_grid, scoring="accuracy", cv=5, verbose=1, n_jobs=-1)
grid.fit(X_train, y_train)

best_knn = grid.best_estimator_
print("Best Parameters:", grid.best_params_)

# ===============================================================
# 6. EVALUATION
# ===============================================================

y_pred = best_knn.predict(X_test)
y_prob = best_knn.predict_proba(X_test)

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average="macro")
rec = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

try:
    auc = roc_auc_score(to_categorical(y_test), y_prob, multi_class="ovr", average="macro")
except Exception:
    auc = np.nan

print("\n=== KNN Performance (NCBI Direct Data) ===")
print(f"Accuracy : {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall   : {rec:.4f}")
print(f"F1-Score : {f1:.4f}")
print(f"AUC      : {auc:.4f}")
